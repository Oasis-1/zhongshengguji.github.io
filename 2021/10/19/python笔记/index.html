<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="安装https:&#x2F;&#x2F;api.bilibili.com&#x2F;pgc&#x2F;page&#x2F;feed?wid&#x3D;10012&amp;cursor&#x3D;1&amp;platform&#x3D;web feed?wid&#x3D;10012&amp;cursor&#x3D;8&amp;platform&#x3D;web B站电影的接口">
<meta property="og:type" content="article">
<meta property="og:title" content="python笔记">
<meta property="og:url" content="http://example.com/2021/10/19/python%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Oasis">
<meta property="og:description" content="安装https:&#x2F;&#x2F;api.bilibili.com&#x2F;pgc&#x2F;page&#x2F;feed?wid&#x3D;10012&amp;cursor&#x3D;1&amp;platform&#x3D;web feed?wid&#x3D;10012&amp;cursor&#x3D;8&amp;platform&#x3D;web B站电影的接口">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20210901113257364.png">
<meta property="og:image" content="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20210901115335007.png">
<meta property="og:image" content="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20211004124112069.png">
<meta property="article:published_time" content="2021-10-19T10:27:16.000Z">
<meta property="article:modified_time" content="2021-11-13T08:59:59.577Z">
<meta property="article:author" content="王一">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20210901113257364.png">

<link rel="canonical" href="http://example.com/2021/10/19/python%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>python笔记 | Oasis</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Oasis</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/19/python%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/1.gif">
      <meta itemprop="name" content="王一">
      <meta itemprop="description" content="你进入游戏行业，就是为了让孩子们上瘾，让人们点击广告吗———美食家五叔评《纪念碑谷》">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Oasis">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          python笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-19 18:27:16" itemprop="dateCreated datePublished" datetime="2021-10-19T18:27:16+08:00">2021-10-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-13 16:59:59" itemprop="dateModified" datetime="2021-11-13T16:59:59+08:00">2021-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>40k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>37 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><a target="_blank" rel="noopener" href="https://api.bilibili.com/pgc/page/feed?wid=10012&amp;cursor=1&amp;platform=web">https://api.bilibili.com/pgc/page/feed?wid=10012&amp;cursor=1&amp;platform=web</a></p>
<p>feed?wid=10012&amp;cursor=8&amp;platform=web</p>
<p>B站电影的接口</p>
<span id="more"></span>

<h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p><a target="_blank" rel="noopener" href="https://www.python.org/">https://www.python.org/</a></p>
<p>第一个界面下面有个添加path可以勾上</p>
<p>第二个界面全选</p>
<p>第三个界面只选默认三个就行了</p>
<h3 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h3><p>pip应该类似于maven一样，进行包的管理，后期学习scrapy需要使用它</p>
<p>测试是否安装使用 <code>pip -V</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\WINDOWS\system32&gt;pip -V</span><br><span class="line">pip 21.2.3 from D:\study\py\lib\site-packages\pip (python 3.9)</span><br></pre></td></tr></table></figure>

<p>如果出现问题后可以查看path的环境变量是否配置</p>
<p>D:\study\py\Scripts</p>
<h3 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h3><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">D:\&gt;<span class="title">cd</span>  <span class="title">study</span>\<span class="title">py</span>\<span class="title">Scripts</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">study</span>\<span class="title">py</span>\<span class="title">Scripts</span>&gt;<span class="title">pip</span> <span class="title">install</span> <span class="title">ipython</span></span></span><br><span class="line"><span class="function"><span class="title">Collecting</span> <span class="title">ipython</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>pip install &lt;包名&gt; 安装指定的包</li>
<li>pip uninstall&lt;包名&gt;删除指定的包</li>
<li>pip list 显示已经安装的包</li>
<li>pip freeze 显示已经安装的包，并且已指定的格式显示</li>
</ul>
<h3 id="更改下载的地址"><a href="#更改下载的地址" class="headerlink" title="更改下载的地址"></a>更改下载的地址</h3><p>运行pip install命令会从网站上下载指定的python包，默认是从<code>https:/lfiles.pythonhosted.org/</code>网站上下载。这是个国外的网站，遇到网络情况不好的时候，可能会下载失败，我们可以通过命令，修改pip现在软件时的源。</p>
<p>格式:</p>
<p><code>pip install包名 -i国内源地址</code></p>
<p>示例:</p>
<p><code>pip install ipython -i https://pypi.mirrors.ustc.edu.cn/simple/</code></p>
<p>就是从中国科技大学(ustc)的服务器上下载requests(基于python的第三方web框架)</p>
<p>国内常用的pip下载源列表:</p>
<ul>
<li>阿里云<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/pypi/simple/">http://mirrors.aliyun.com/pypi/simple/</a></li>
<li>中国科技大学<a target="_blank" rel="noopener" href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a></li>
<li>豆瓣(douban) <a target="_blank" rel="noopener" href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a></li>
<li>清华大学<a target="_blank" rel="noopener" href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a></li>
<li>中国科学技术大学<a target="_blank" rel="noopener" href="http://pypi.mirrors.ustc.edu.cn/simple/">http://pypi.mirrors.ustc.edu.cn/simple/</a></li>
</ul>
<h3 id="运行python"><a href="#运行python" class="headerlink" title="运行python"></a>运行python</h3><p>三种方式</p>
<ul>
<li><p>终端<code>python 文件路径</code></p>
</li>
<li><p>ipython</p>
<p>终端输入<code>ipython</code>然后进行编写只不过比原来增加高亮提示罢了</p>
</li>
<li><p>pycharm</p>
</li>
</ul>
<h2 id="pycharm"><a href="#pycharm" class="headerlink" title="pycharm"></a>pycharm</h2><p><img src="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20210901113257364.png" alt="image-20210901113257364"></p>
<h3 id="每次创建文件自动添加注释"><a href="#每次创建文件自动添加注释" class="headerlink" title="每次创建文件自动添加注释"></a>每次创建文件自动添加注释</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># _*_ coding:utf-8 _*_</span></span><br><span class="line"><span class="comment"># @Time: $&#123;DATE&#125; $&#123;TIME&#125;</span></span><br><span class="line"><span class="comment"># @author:w1</span></span><br><span class="line"><span class="comment"># @File: $&#123;NAME&#125;</span></span><br></pre></td></tr></table></figure>

<p>文件和代码模板里选择python srcipt</p>
<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><p>单行注释用 <code>#</code></p>
<p>多行注释用 ，三个单引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">wwuwuuwuw</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>



<h1 id="python-1"><a href="#python-1" class="headerlink" title="python"></a>python</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p><img src="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20210901115335007.png" alt="image-20210901115335007"></p>
<p>list和tuple的区别</p>
<blockquote>
<ol>
<li>列表是动态数组，它们可变且可以重设长度（改变其内部元素的个数）。</li>
<li>元组是静态数组，它们不可变，且其内部数据一旦创建便无法改变。</li>
<li>元组缓存于Python运行时环境，这意味着我们每次使用元组时无须访问内核去分配内存。</li>
</ol>
<p>这些区别结实率两者在设计哲学上的不同：</p>
<ul>
<li>列表可被用于保存多个互相独立对象的数据集合</li>
<li>元组用于描述一个不会改不安的事务的多个属性</li>
</ul>
</blockquote>
<p>list的变量有<code>append</code>方法，可以添加东西，tuple没有</p>
<p>但是两者都有add方法，可以把两个list或者tuple结合在一起</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">name=[<span class="string">&#x27;qwe&#x27;</span>,<span class="string">&#x27;ww&#x27;</span>,<span class="string">&#x27;ee&#x27;</span>];</span><br><span class="line"><span class="built_in">print</span>(name,<span class="built_in">type</span>(name));</span><br><span class="line">name.append(<span class="number">9</span>);</span><br><span class="line">name=name.__add__(name);</span><br><span class="line"><span class="built_in">print</span>(name,<span class="built_in">type</span>(name));</span><br><span class="line"><span class="built_in">print</span>(name.__len__());</span><br><span class="line">n=(<span class="string">&#x27;q&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,<span class="string">&#x27;e&#x27;</span>);</span><br><span class="line"><span class="built_in">print</span>(n,<span class="built_in">type</span>(n));</span><br><span class="line">n=n.__add__(n);</span><br><span class="line"><span class="built_in">print</span>(n,<span class="built_in">type</span>(n));</span><br></pre></td></tr></table></figure>

<p>dict就是hashmap</p>
<h2 id="查看变量类型"><a href="#查看变量类型" class="headerlink" title="查看变量类型"></a>查看变量类型</h2><p>变量没有数据类型，数据才有类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">name=&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;w1&#x27;</span>,<span class="string">&#x27;age&#x27;</span>:<span class="number">5</span>&#125;;</span><br><span class="line"><span class="built_in">print</span>(name,<span class="built_in">type</span>(name));</span><br><span class="line">name=<span class="string">&quot;l&quot;</span>;</span><br><span class="line"><span class="built_in">print</span>(name,<span class="built_in">type</span>(name));</span><br><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;w1&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">5</span>&#125; &lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">dict</span>&#x27;&gt;</span></span><br><span class="line"><span class="class"><span class="title">l</span> &lt;<span class="title">class</span> &#x27;<span class="title">str</span>&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h2><ul>
<li>字母，下划线，数字组成，数字不能开头</li>
<li>严格区分大小写</li>
<li>不能使用关键字</li>
</ul>
<h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><p>float转换成int时候，小数部分直接截掉</p>
<p>字符串如果包含非法字符就会转换失败</p>
<h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><p>//=是整除</p>
<p>**=是幂运算</p>
<p>与或非</p>
<p>and or not （短路）</p>
<p>&amp; | （没有取反的符号）</p>
<h2 id="for"><a href="#for" class="headerlink" title="for"></a>for</h2><p>for  变量 in 遍历对象</p>
<p>遍历对象常用range</p>
<p>range的格式range（初始值，结束值，步长）</p>
<p>左闭右开，初始值默认0，步长默认1，不包含结束值</p>
<h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><h3 id="增"><a href="#增" class="headerlink" title="增"></a>增</h3><p>append（）添加到最后</p>
<p>insert（index，object）</p>
<p>sum.extend（sum1）得到结果是他俩前后连一块的集合</p>
<h3 id="删"><a href="#删" class="headerlink" title="删"></a>删</h3><p>del根据下表移除</p>
<p>pop最后一个，出栈</p>
<p>remove根据值移除</p>
<h3 id="改"><a href="#改" class="headerlink" title="改"></a>改</h3><p>通过下标直接赋值</p>
<h3 id="查"><a href="#查" class="headerlink" title="查"></a>查</h3><p>变量 in 对象   存在就为true</p>
<p>not in</p>
<h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>元组里的元素是不能修改的</p>
<p>定义只有一个元素的元组，需要在后面加个逗号</p>
<h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><p>字符串，列表，元组都支持切片</p>
<p>取下标的时候，可以用冒号</p>
<p>对象【start：end：step】</p>
<p>默认【0：len：1】</p>
<h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><h3 id="增-1"><a href="#增-1" class="headerlink" title="增"></a>增</h3><p>添加跟修改相同，</p>
<p>a[‘法外狂徒’]=223</p>
<p>当添加一个key相同的键值对，就是修改，当key不存在时候，就是添加操作</p>
<h3 id="删-1"><a href="#删-1" class="headerlink" title="删"></a>删</h3><ol>
<li><p>del  字典【key】删除一个元素</p>
</li>
<li><p>del 字典，直接将整个字典删除</p>
</li>
<li><p>字典.clear   清空字典，但是保留对象</p>
</li>
</ol>
<h3 id="改-1"><a href="#改-1" class="headerlink" title="改"></a>改</h3><p>a[‘法外狂徒’]=223</p>
<p>没有set方法，只能通过这一种修改</p>
<h3 id="查-1"><a href="#查-1" class="headerlink" title="查"></a>查</h3><p>person【’key‘】  获取不存在的key的时候</p>
<p>person.get（’key‘）</p>
<h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a.keys():<span class="comment">#遍历key</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a.values():<span class="comment">#遍历value</span></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> a.items():<span class="comment">#遍历key和value</span></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> a.items():<span class="comment">#遍历元素</span></span><br></pre></td></tr></table></figure>

<h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><p>open（文件路径，访问模式）</p>
<p>访问模式有w r a</p>
<p>w写，光标在开头</p>
<p>r读，有返回值</p>
<p>a追加，光标在最后</p>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>讲一个对象序列化就是</p>
<p>将对象变成字符串，然后通过write写入文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">a=&#123;<span class="string">&#x27;法外狂徒&#x27;</span>:<span class="string">&#x27;zhangsan&#x27;</span>,<span class="string">&#x27;wuw&#x27;</span>:<span class="string">&#x27;吴签&#x27;</span>&#125;</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;test.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="comment">#fp.write(json.dumps(a))</span></span><br><span class="line">json.dump(a,fp)</span><br><span class="line">fp.close()</span><br><span class="line">fp=<span class="built_in">open</span>(<span class="string">&#x27;test.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">con=fp.readlines()</span><br><span class="line"><span class="built_in">print</span>(con,<span class="built_in">type</span>(con))</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>

<p>fp.write(json.dumps(a))等价于json.dump(a,fp)</p>
<h2 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h2><p>json.load（文件）</p>
<p>json.loads（字符串）</p>
<p>read和readline都是字符串，readlines读完直接变成列表</p>
<h1 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h1><p>try…except</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment">#可能出现异常的代码</span></span><br><span class="line"><span class="keyword">except</span> 异常类型</span><br><span class="line">    <span class="comment">#提示</span></span><br></pre></td></tr></table></figure>

<h1 id="urllib库"><a href="#urllib库" class="headerlink" title="urllib库"></a>urllib库</h1><p>通过urllib获取网页的源码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过urllib获取网页的源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#(1)定义一个url</span></span><br><span class="line">url=<span class="string">&#x27;http://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment">#(2)模拟浏览器向服务器发送请求</span></span><br><span class="line">response = urllib.request.urlopen(url)</span><br><span class="line"><span class="comment">#(3)获取响应中的页面源码</span></span><br><span class="line"><span class="comment">#read返回的是二进制数据，开头带B，二进制--&gt;字符串,使用decode（’编码格式‘）</span></span><br><span class="line">content=response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#(4)输出</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h2 id="一个类型，六个方法"><a href="#一个类型，六个方法" class="headerlink" title="一个类型，六个方法"></a>一个类型，六个方法</h2><p>resp是HTTPResponse的类型</p>
<p>六个方法是read readlin readlines getcode geturl getheaders</p>
<p>getcode 返回状态码 200之类的</p>
<p>getrul  返回url地址  baidu.com</p>
<p>getheaders 返回请求头  是一堆键值对</p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>使用</p>
<p>urllib.request.urlretrieve（url，’文件名‘）</p>
<p>url可以是html，图片，视频</p>
<h1 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h1><p>反爬手段</p>
<ol>
<li><p>修改User-Agent，User-Agent是一个字符串，存储着用户的操作系统，版本，cpu类型，浏览器标识，浏览器渲染引擎，浏览器语言，浏览器插件。</p>
</li>
<li><p>代理IP</p>
<p>西次代理</p>
<p>快代理</p>
<p>高匿名，匿名，透明代理，区别就是是否知道使用了代理，真实IP</p>
</li>
<li><p>验证码访问</p>
<p>打码平台</p>
<p>​    云打码平台</p>
<p>​    超级🦅</p>
</li>
<li><p>动态加载网页  返回的是js数据</p>
<p>selenium驱动真实的浏览器发送请求</p>
</li>
<li><p>数据加密</p>
<p>分析js代码</p>
</li>
</ol>
<h2 id="请求对象的定制（UA反爬）"><a href="#请求对象的定制（UA反爬）" class="headerlink" title="请求对象的定制（UA反爬）"></a>请求对象的定制（UA反爬）</h2><p>使用https爬取百度的时候，百度会因为请求头的不完整，返回的也不完整，这时候就需要定制一个完整的请求对象（5.1里url改成https就可以直接出现改错误）</p>
<p>User-Agent</p>
<blockquote>
<p>修改User-Agent，User-Agent是一个字符串，存储着用户的操作系统，版本，cpu类型，浏览器标识，浏览器渲染引擎，浏览器语言，浏览器插件。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过urllib获取网页的源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#(1)定义一个url</span></span><br><span class="line">header=&#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line"><span class="comment">#(2)模拟浏览器向服务器发送请求 重点在这下面两行</span></span><br><span class="line">request=urllib.request.Request(url=url,headers=header)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="comment">#(3)获取响应中的页面源码</span></span><br><span class="line"><span class="comment">#read返回的是二进制数据，开头带B，二进制--&gt;字符串,使用decode（’编码格式‘）</span></span><br><span class="line">content=response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#(4)输出</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h2 id="URL中有中文的时候的解决办法"><a href="#URL中有中文的时候的解决办法" class="headerlink" title="URL中有中文的时候的解决办法"></a>URL中有中文的时候的解决办法</h2><h3 id="quote方法"><a href="#quote方法" class="headerlink" title="quote方法"></a>quote方法</h3><p>英文意思是引用</p>
<p>name=urllib.parse.<strong>quote</strong>(‘毛不易’)<br>url+=name</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过urllib获取网页的源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#(1)定义一个url</span></span><br><span class="line">header=&#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s?wd=&#x27;</span></span><br><span class="line"><span class="comment">#(2)模拟浏览器向服务器发送请求</span></span><br><span class="line">name=urllib.parse.quote(<span class="string">&#x27;毛不易&#x27;</span>)</span><br><span class="line">url+=name</span><br><span class="line"><span class="built_in">print</span>(url)</span><br><span class="line">request=urllib.request.Request(url=url,headers=header)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="comment">#(3)获取响应中的页面源码</span></span><br><span class="line"><span class="comment">#read返回的是二进制数据，开头带B，二进制--&gt;字符串,使用decode（’编码格式‘）</span></span><br><span class="line">content=response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#(4)输出</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h3 id="urlencode方法"><a href="#urlencode方法" class="headerlink" title="urlencode方法"></a>urlencode方法</h3><p>data={<br>    ‘wd’: ‘周杰伦’,<br>    ‘sex’: ‘男’,<br>    ‘location’: ‘台湾’<br>}<br>new_data=urllib.parse.<strong>urlencode(data)</strong><br>print(new_data)<br>url+=new_data</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过urllib获取网页的源码</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#(1)定义一个url</span></span><br><span class="line">header=&#123;</span><br><span class="line"><span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s?&#x27;</span></span><br><span class="line"><span class="comment">#(2)模拟浏览器向服务器发送请求</span></span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;周杰伦&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sex&#x27;</span>: <span class="string">&#x27;男&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;location&#x27;</span>: <span class="string">&#x27;台湾&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">new_data=urllib.parse.urlencode(data)</span><br><span class="line"><span class="built_in">print</span>(new_data)</span><br><span class="line">url+=new_data</span><br><span class="line">request=urllib.request.Request(url=url,headers=header)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line"><span class="comment">#(3)获取响应中的页面源码</span></span><br><span class="line"><span class="comment">#read返回的是二进制数据，开头带B，二进制--&gt;字符串,使用decode（’编码格式‘）</span></span><br><span class="line">content=response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#(4)输出</span></span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br></pre></td></tr></table></figure>

<h2 id="post请求"><a href="#post请求" class="headerlink" title="post请求"></a>post请求</h2><p>post请求参数不能出现的url中</p>
<p>并且需要encode指定编码（decode是解码）</p>
<p>data=urllib.parse.urlencode(data).encode(‘utf-8’)<br>request=urllib.request.Request(url=url,data=data,headers=header)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#先获取url，请求头，data</span></span><br><span class="line">url=<span class="string">&quot;https://fanyi.baidu.com/sug&quot;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;love&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#把data从对象转换成byte，使用utf8的编码</span></span><br><span class="line">data=urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#制作请求头</span></span><br><span class="line">request=urllib.request.Request(url=url,data=data,headers=headers)</span><br><span class="line"><span class="comment">#模拟浏览器访问</span></span><br><span class="line">respone=urllib.request.urlopen(request)</span><br><span class="line"><span class="built_in">print</span>(respone)</span><br><span class="line"><span class="comment">#拿到后再使用encode解码</span></span><br><span class="line"><span class="built_in">print</span>(respone.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h2 id="get请求批量爬取。"><a href="#get请求批量爬取。" class="headerlink" title="get请求批量爬取。"></a>get请求批量爬取。</h2><p>爬取豆瓣十页（得到十个json文件）</p>
<p>首先分析到豆瓣的servlet想赢的是通过get请求里面的start和limit决定的内容不一样的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#1.请求对象的定制</span></span><br><span class="line"><span class="comment">#2.获取响应数据</span></span><br><span class="line"><span class="comment">#3.下载数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creat_requst</span>(<span class="params">page</span>):</span></span><br><span class="line">    base_url = <span class="string">&#x27;https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;&#x27;</span></span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;start&#x27;</span>:(page-<span class="number">1</span>)*<span class="number">20</span>,</span><br><span class="line">        <span class="string">&#x27;limit&#x27;</span>:<span class="number">20</span></span><br><span class="line">    &#125;</span><br><span class="line">    data = urllib.parse.urlencode(data)</span><br><span class="line">    url=base_url+data</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    requst=urllib.request.Request(url=url,headers=headers)</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    <span class="keyword">return</span> requst</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">request</span>):</span></span><br><span class="line">    response=urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down_load</span>(<span class="params">page,content</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;douban&#x27;</span>+ <span class="built_in">str</span>(page)+<span class="string">&#x27;.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页&#x27;</span>))</span><br><span class="line">    end=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start,end+<span class="number">1</span>):</span><br><span class="line">        request=creat_requst(i)</span><br><span class="line">        content=get_content(request)</span><br><span class="line">        down_load(i,content)</span><br></pre></td></tr></table></figure>

<h2 id="post请求爬十页"><a href="#post请求爬十页" class="headerlink" title="post请求爬十页"></a>post请求爬十页</h2><p>跟豆瓣的区别</p>
<p>url直接复制过来就能用</p>
<p>data使用form data里的数据</p>
<p>data转换的时候，用下encode编码下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#1.请求对象的定制</span></span><br><span class="line"><span class="comment">#2.获取响应数据</span></span><br><span class="line"><span class="comment">#3.下载数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creat_requst</span>(<span class="params">page</span>):</span></span><br><span class="line">    url = <span class="string">&#x27;http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname&#x27;</span></span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;cname&#x27;</span>: <span class="string">&#x27;郑州&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pageIndex&#x27;</span>: page,</span><br><span class="line">        <span class="string">&#x27;pageSize&#x27;</span>: <span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    data = urllib.parse.urlencode(data).encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    requst=urllib.request.Request(url=url,headers=headers,data=data)</span><br><span class="line">    <span class="built_in">print</span>(url)</span><br><span class="line">    <span class="keyword">return</span> requst</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">request</span>):</span></span><br><span class="line">    response=urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down_load</span>(<span class="params">page,content</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;douban&#x27;</span>+ <span class="built_in">str</span>(page)+<span class="string">&#x27;.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(content)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页&#x27;</span>))</span><br><span class="line">    end=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start,end+<span class="number">1</span>):</span><br><span class="line">        request=creat_requst(i)</span><br><span class="line">        content=get_content(request)</span><br><span class="line">        down_load(i,content)</span><br></pre></td></tr></table></figure>

<h2 id="handle"><a href="#handle" class="headerlink" title="handle"></a>handle</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">requst=urllib.request.Request(url=url)</span><br><span class="line"><span class="comment">#无法定制请求头</span></span><br><span class="line">requst=urllib.request.Request(url=url,headers=headers,data=data)</span><br><span class="line"><span class="comment">#可以定制请求头</span></span><br><span class="line">Handle</span><br><span class="line"><span class="comment">#更高级的定制请求头</span></span><br></pre></td></tr></table></figure>

<p>handler  build_opener   open</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#1.请求对象的定制</span></span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?wd=ip&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#2.获取响应数据</span></span><br><span class="line">requst=urllib.request.Request(url=url,headers=headers)</span><br><span class="line"></span><br><span class="line">proxies=&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;51.38.19.180：80&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#handler  build_opener   open</span></span><br><span class="line">handler=urllib.request.ProxyHandler(proxies=proxies)</span><br><span class="line">opener=urllib.request.build_opener()</span><br><span class="line">response=opener.<span class="built_in">open</span>(requst)</span><br><span class="line"><span class="comment">#response=urllib.request.urlopen(requst)</span></span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.下载数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;weibo.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br></pre></td></tr></table></figure>

<p>上面这段是失败的</p>
<h2 id="代理池"><a href="#代理池" class="headerlink" title="代理池"></a>代理池</h2><p>核心是是用random.choice，从池子里选一个</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">proxies_pool=[</span><br><span class="line">    &#123;&#x27;http&#x27;:&#x27;51.38.19.180：80&#x27;&#125;,</span><br><span class="line">    &#123;&#x27;http&#x27;:&#x27;51.38.19.180：80&#x27;&#125;,</span><br><span class="line">]</span><br><span class="line">import random</span><br><span class="line">proxies=random.choice(proxies_pool)</span><br></pre></td></tr></table></figure>

<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><h2 id="Xpath-lxml"><a href="#Xpath-lxml" class="headerlink" title="Xpath(lxml)"></a>Xpath(lxml)</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_43576837/article/details/108410989">https://blog.csdn.net/qq_43576837/article/details/108410989</a></p>
<p>本质就一谷歌插件</p>
<p>还需要进<code>D:\study\py\Scripts</code>里执行<code>pip instaal lxml -i https://pypi.douban.com    </code></p>
<p>执行结束后可能会报错，说需要更新版本什么的，不用管</p>
<p>进到pycharm里<code>from lxml import etree</code>没有报错，就是安装成功了</p>
<p>一般用lxml解析本地文件和服务器响应文件</p>
<p>本地文件etree.parse(‘XX.html’)</p>
<p>服务器文件：etree.html（respone.read（）.decode（‘utf-8’））</p>
<p>4.html_tree.xpath(xpath路径)</p>
<h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><p>下面列出了最有用的路径表达式：</p>
<table>
<thead>
<tr>
<th>nodename</th>
<th>选取此节点的所有子节点。</th>
</tr>
</thead>
<tbody><tr>
<td>/</td>
<td>从根节点选取。</td>
</tr>
<tr>
<td>//</td>
<td>从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点。</td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点。</td>
</tr>
<tr>
<td>@</td>
<td>选取属性。</td>
</tr>
</tbody></table>
<p>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<table>
<thead>
<tr>
<th align="left">路径表达式</th>
<th align="left">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">/bookstore/book[1]</td>
<td align="left">选取属于 bookstore 子元素的第一个 book 元素。</td>
</tr>
<tr>
<td align="left">/bookstore/book[last()]</td>
<td align="left">选取属于 bookstore 子元素的最后一个 book 元素。</td>
</tr>
<tr>
<td align="left">/bookstore/book[last()-1]</td>
<td align="left">选取属于 bookstore 子元素的倒数第二个 book 元素。</td>
</tr>
<tr>
<td align="left">/bookstore/book[position()&lt;3]</td>
<td align="left">选取最前面的两个属于 bookstore 元素的子元素的 book 元素。</td>
</tr>
<tr>
<td align="left">//title[@lang]</td>
<td align="left">选取所有拥有名为 lang 的属性的 title 元素。</td>
</tr>
<tr>
<td align="left">//title[@lang=’eng’]</td>
<td align="left">选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。</td>
</tr>
<tr>
<td align="left">/bookstore/book[price&gt;35.00]</td>
<td align="left">选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
<tr>
<td align="left">/bookstore/book[price&gt;35.00]/title</td>
<td align="left">选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#爬取百度的“百度一下”四个字</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#制作请求头</span></span><br><span class="line">request=urllib.request.Request(url=url,headers=headers)</span><br><span class="line"><span class="comment">#模拟浏览器发送请求</span></span><br><span class="line">response=urllib.request.urlopen(request)</span><br><span class="line">content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"><span class="comment">#解析网页只要想要的数据</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment">#解析响应文件，将源码导入到lxml里</span></span><br><span class="line">tree=etree.HTML(content)</span><br><span class="line"><span class="comment">#根据公式取想要的数据</span></span><br><span class="line">res=tree.xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<p>P72 站长素材采集解决图片不清晰问题<br>建议使用切片，src = “http:”+url_list【i】【:-6】+“.jpg”<br>缩略图的地址比正常图片地址多了一个_s，去掉以后下载下来的就是原图，而不是缩略图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#1.请求对象的定制</span></span><br><span class="line"><span class="comment">#2.获取响应数据</span></span><br><span class="line"><span class="comment">#3.下载数据</span></span><br><span class="line"><span class="comment">#//div[@id=&quot;container&quot;]//a/img/@src</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creat_requst</span>(<span class="params">page</span>):</span></span><br><span class="line">    <span class="keyword">if</span> page==<span class="number">1</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/huanghuntupian.html&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">&#x27;https://sc.chinaz.com/tupian/huanghuntupian_&#x27;</span>+<span class="built_in">str</span>(page)+<span class="string">&#x27;.html&#x27;</span></span><br><span class="line">    headers=&#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    requst=urllib.request.Request(url=url,headers=headers)</span><br><span class="line">    <span class="keyword">return</span> requst</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span>(<span class="params">request</span>):</span></span><br><span class="line">    response=urllib.request.urlopen(request)</span><br><span class="line">    content = response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> content</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down_load</span>(<span class="params">page,content</span>):</span></span><br><span class="line">    <span class="comment"># 解析响应文件，将源码导入到lxml里</span></span><br><span class="line">    tree = etree.HTML(content)</span><br><span class="line">    <span class="comment"># 根据公式取想要的数据</span></span><br><span class="line">    name_list = tree.xpath(<span class="string">&#x27;//div[@id=&quot;container&quot;]//a/img/@alt&#x27;</span>)</span><br><span class="line">    <span class="comment">#涉及到图片时，网站一般都会进行懒加载，要爬取他加载之前的数据</span></span><br><span class="line">    res = tree.xpath(<span class="string">&#x27;//div[@id=&quot;container&quot;]//a/img/@src2&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(name_list)</span><br><span class="line">    <span class="built_in">print</span>(res)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res)):</span><br><span class="line">        urllib.request.urlretrieve(url=<span class="string">&#x27;https:&#x27;</span>+res[i][:-<span class="number">6</span>]+<span class="string">&#x27;.jpg&#x27;</span>, filename=<span class="string">&#x27;img/&#x27;</span>+<span class="built_in">str</span>(name_list[i]) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入起始页&#x27;</span>))</span><br><span class="line">    end=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;请输入结束页&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start,end+<span class="number">1</span>):</span><br><span class="line">        request=creat_requst(i)</span><br><span class="line">        content=get_content(request)</span><br><span class="line">        down_load(i,content)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#爬取bing图片，慢慢研究</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: (<span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) &quot;</span></span><br><span class="line">                   <span class="string">&quot;Gecko/20100101 Firefox/64.0&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_index</span>(<span class="params">resolution, index=<span class="number">1</span></span>):</span></span><br><span class="line">    url = <span class="string">f&quot;https://bing.ioliu.cn/ranking?p=<span class="subst">&#123;index&#125;</span>&quot;</span></span><br><span class="line">    res = requests.get(url, headers=headers)</span><br><span class="line">    urls = re.findall(<span class="string">&#x27;pic=(.*?)\\.jpg&#x27;</span>, res.text)</span><br><span class="line">    _old_resolution = urls[<span class="number">1</span>].split(<span class="string">&quot;_&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> &#123;url.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>].replace(_old_resolution, resolution): url.replace(_old_resolution, resolution) + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">            <span class="keyword">for</span> url <span class="keyword">in</span> urls&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_pic</span>(<span class="params">pics, i</span>):</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;C:\\必应壁纸&#x27;</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        os.mkdir(<span class="string">&#x27;C:\\必应壁纸&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;目录创建成功&#x27;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        j = (i - <span class="number">1</span>) * <span class="number">12</span></span><br><span class="line">        <span class="keyword">for</span> pic_name, pic_url <span class="keyword">in</span> pics.items():</span><br><span class="line">            res = requests.get(pic_url, headers=headers)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;C:\\必应壁纸\\img_&quot;</span> + <span class="built_in">str</span>(j) + <span class="string">&quot;.jpg&quot;</span>, mode=<span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(res.content)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;pic_name&#125;</span> 下载完成&quot;</span>)</span><br><span class="line">            j = j + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;第%d张下载出错&quot;</span> % j, e)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_index</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;必应壁纸下载工具, 本工具未经资源站授权.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;仅做学习和交流之用, 随时有可能停止维护.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;目前资源站收容页数为128,当前仅提供1920x1080分辨率下载&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        sleep(<span class="number">0.1</span>)</span><br><span class="line">        index = <span class="built_in">input</span>(<span class="string">&quot;请输入要下载的页数(Max=128):&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> index == <span class="string">&quot;Q&quot;</span>:</span><br><span class="line">                exit()</span><br><span class="line">            index = <span class="number">128</span> <span class="keyword">if</span> <span class="built_in">int</span>(index) &gt; <span class="number">128</span> <span class="keyword">else</span> <span class="built_in">int</span>(index)</span><br><span class="line">            <span class="keyword">return</span> index</span><br><span class="line">        <span class="keyword">except</span> ValueError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;请输入数字, 或输入Q退出!&quot;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    index = input_index()</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> i &lt;= index:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;当前第<span class="subst">&#123;i&#125;</span>页,共需要下载<span class="subst">&#123;index&#125;</span>页&quot;</span>)</span><br><span class="line">        pics = get_index(<span class="string">&quot;1920x1080&quot;</span>, i)</span><br><span class="line">        download_pic(pics, i)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;下载完成,将在3秒后关闭...&quot;</span>)</span><br><span class="line">    sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;2&quot;</span>)</span><br><span class="line">    sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">    sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;0&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="jsonpath"><a href="#jsonpath" class="headerlink" title="jsonpath"></a>jsonpath</h2><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/youring2/p/10942728.html">https://www.cnblogs.com/youring2/p/10942728.html</a></p>
<table>
<thead>
<tr>
<th>XPath</th>
<th>JsonPath</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>/</code></td>
<td><code>$</code></td>
<td>文档根元素</td>
</tr>
<tr>
<td><code>.</code></td>
<td><code>@</code></td>
<td>当前元素</td>
</tr>
<tr>
<td><code>/</code></td>
<td><code>.</code>或<code>[]</code></td>
<td>匹配下级元素</td>
</tr>
<tr>
<td><code>..</code></td>
<td><code>N/A</code></td>
<td>匹配上级元素，JsonPath不支持此操作符</td>
</tr>
<tr>
<td><code>//</code></td>
<td><code>..</code></td>
<td>递归匹配所有子元素</td>
</tr>
<tr>
<td><code>*</code></td>
<td><code>*</code></td>
<td>通配符，匹配下级元素</td>
</tr>
<tr>
<td><code>@</code></td>
<td><code>N/A</code></td>
<td>匹配属性，JsonPath不支持此操作符</td>
</tr>
<tr>
<td><code>[]</code></td>
<td><code>[]</code></td>
<td>下标运算符，根据索引获取元素，<strong>XPath索引从1开始，JsonPath索引从0开始</strong></td>
</tr>
<tr>
<td>`</td>
<td>`</td>
<td><code>[,]</code></td>
</tr>
<tr>
<td><code>N/A</code></td>
<td><code>[start:end:step]</code></td>
<td>数据切片操作，XPath不支持</td>
</tr>
<tr>
<td><code>[]</code></td>
<td><code>?()</code></td>
<td>过滤表达式</td>
</tr>
<tr>
<td><code>N/A</code></td>
<td><code>()</code></td>
<td>脚本表达式，使用底层脚本引擎，XPath不支持</td>
</tr>
<tr>
<td><code>()</code></td>
<td><code>N/A</code></td>
<td>分组，JsonPath不支持</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"><span class="comment">#读取json文件</span></span><br><span class="line">obj = json.load(<span class="built_in">open</span>(<span class="string">&#x27;json/douban5.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"><span class="comment">#选择文件，然后用需要的通配符获取想要的数据</span></span><br><span class="line">tlist = jsonpath.jsonpath(obj, <span class="string">&#x27;$..title&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(tlist)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">#获取这仨</span></span><br><span class="line">url=<span class="string">&#x27;https://dianying.taobao.com/cityAction.json?activityId&amp;_ksTS=1633005693711_63&amp;jsoncallback=jsonp64&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="comment"># &#x27;:authority&#x27;:&#x27; dianying.taobao.com&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:method&#x27;:&#x27; GET&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:path&#x27;:&#x27; /cityAction.json?activityId&amp;_ksTS=1633005693711_63&amp;jsoncallback=jsonp64&amp;action=cityAction&amp;n_s=new&amp;event_submit_doGetAllRegion=true&#x27;,</span></span><br><span class="line">    <span class="comment"># &#x27;:scheme&#x27;:&#x27; https&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;accept&#x27;</span>:<span class="string">&#x27;*/*&#x27;</span>,</span><br><span class="line">    <span class="comment"># &#x27;accept-encoding&#x27;:&#x27; gzip, deflate, br&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;accept-language&#x27;</span>:<span class="string">&#x27;zh-CN,zh;q=0.9&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;cookie&#x27;</span>:<span class="string">&#x27;cna=euh2GV4qgAgCAd9Y1rD9qUhb; t=37fc82327b434db82e7196ac780cf066; cookie2=1fdfe2c6ec7de2b157138f5e0807c70d; v=0; _tb_token_=eb983ae318843; xlly_s=1; tfstk=cO1PBbMJ_7FyPROQBQOUOvDDeERRZL_l-j86ETfbIJzaYQ9lieoponF9uegqxLf..; l=eB_Pvv6ujvmov1K3BO5Cnurza7790IOb4sPzaNbMiInca6Qh9Fw3nNCLF3TvWdtjgtCAdetrrLZHDRLHR3xg5c0c0xb0hlYtFxvO.; isg=BOTkUjzYWQLK7KxtAWkG6YcSteLWfQjngEPQ5P4EY69yqYRzJo94d1cHaQGxcUA_&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;referer&#x27;</span>:<span class="string">&#x27;https://www.taobao.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua&#x27;</span>:<span class="string">&#x27;&quot;Chromium&quot;;v=&quot;94&quot;, &quot;Google Chrome&quot;;v=&quot;94&quot;, &quot;;Not A Brand&quot;;v=&quot;99&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-mobile&#x27;</span>:<span class="string">&#x27;?0&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-ch-ua-platform&#x27;</span>:<span class="string">&#x27;&quot;Windows&quot;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-dest&#x27;</span>:<span class="string">&#x27;script&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-mode&#x27;</span>:<span class="string">&#x27;no-cors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;sec-fetch-site&#x27;</span>:<span class="string">&#x27;same-site&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#制作请求头</span></span><br><span class="line">request=urllib.request.Request(url=url,headers=headers)</span><br><span class="line"><span class="comment">#模拟浏览器发送get请求</span></span><br><span class="line">response=urllib.request.urlopen(request)</span><br><span class="line"><span class="comment">#读取响应</span></span><br><span class="line">content=response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="comment">#切割，因为这个特殊返回的json带json64的头，把不要的字符删掉</span></span><br><span class="line">content=content.split(<span class="string">&#x27;(&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;)&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#下载到本地</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;json/taopiapiao.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content)</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#读取json文件</span></span><br><span class="line">    obj=json.load(<span class="built_in">open</span>(<span class="string">&#x27;json/taopiapiao.json&#x27;</span>,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    <span class="comment">#选择文件，然后用需要的通配符获取想要的数据</span></span><br><span class="line">    l=jsonpath.jsonpath(obj,<span class="string">&#x27;$..regionName&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(l)</span><br></pre></td></tr></table></figure>

<h2 id="BeautifulSoup-BS4"><a href="#BeautifulSoup-BS4" class="headerlink" title="BeautifulSoup(BS4)"></a>BeautifulSoup(BS4)</h2><p>优点：人性化</p>
<p>缺点：效率慢</p>
<h2 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33542626">https://zhuanlan.zhihu.com/p/33542626</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/6c82c965c014">https://www.jianshu.com/p/6c82c965c014</a></p>
<p>可以模拟真实的浏览器发送请求</p>
<p>类似于按键精灵</p>
<p><a target="_blank" rel="noopener" href="https://www.jd.com/%E5%85%B8%E5%9E%8B%E7%9A%84%E4%BA%AC%E4%B8%9C%EF%BC%8C%E8%AF%86%E5%88%AB%E7%88%AC%E8%99%AB%E4%B8%8D%E7%BB%99%E6%95%B0%E6%8D%AE%EF%BC%8C">https://www.jd.com/典型的京东，识别爬虫不给数据，</a> 按键精灵模拟后，可以获得browser.pae_sourse()可以获得源码</p>
<p>下载的时候版本要对着<code>https://chromedriver.storage.googleapis.com/index.html</code></p>
<p>浏览器版本和驱动版本必须相同，向上向下，都无法兼容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入selenium</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="comment">#2.创建浏览器操作对象</span></span><br><span class="line">path=<span class="string">&#x27;chromedriver2.exe&#x27;</span></span><br><span class="line">browser=webdriver.Chrome(path)</span><br><span class="line"><span class="comment">#3.访问网站</span></span><br><span class="line">url=<span class="string">&#x27;https://3.cn/&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line">content=browser.page_source</span><br><span class="line"><span class="built_in">print</span>(content)	</span><br></pre></td></tr></table></figure>

<h3 id="定位元素"><a href="#定位元素" class="headerlink" title="定位元素"></a>定位元素</h3><p>常用的三个by_id，by_xpath，by_css_selector</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#1.导入selenium</span><br><span class="line">from selenium import webdriver</span><br><span class="line">#2.创建浏览器操作对象</span><br><span class="line">path=&#x27;chromedriver2.exe&#x27;</span><br><span class="line">browser=webdriver.Chrome(path)</span><br><span class="line">#3.访问网站</span><br><span class="line">url=&#x27;https://baidu.com/&#x27;</span><br><span class="line">browser.get(url)</span><br><span class="line">#根据id的值找到对象</span><br><span class="line">content=browser.find_element_by_id(&#x27;su&#x27;)</span><br><span class="line">print(content)</span><br><span class="line">#根据name的值找到对象</span><br><span class="line">#content=browser.find_elements_by_name(&#x27;f&#x27;)</span><br><span class="line">#根据xpath找到对象</span><br><span class="line">content=browser.find_element_by_xpath(&#x27;//input[@id=&quot;su&quot;]&#x27;)</span><br><span class="line">print(content)</span><br><span class="line">#bs4语法找到对象</span><br><span class="line">content=browser.find_element_by_css_selector(&#x27;#su&#x27;)</span><br><span class="line">print(content)</span><br></pre></td></tr></table></figure>

<h3 id="获取元素信息"><a href="#获取元素信息" class="headerlink" title="获取元素信息"></a>获取元素信息</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入selenium</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="comment">#2.创建浏览器操作对象</span></span><br><span class="line">path=<span class="string">&#x27;chromedriver2.exe&#x27;</span></span><br><span class="line">browser=webdriver.Chrome(path)</span><br><span class="line"><span class="comment">#3.访问网站</span></span><br><span class="line">url=<span class="string">&#x27;https://baidu.com/&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"><span class="comment">#根据id的值找到对象</span></span><br><span class="line">content=browser.find_element_by_id(<span class="string">&#x27;su&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(content)</span><br><span class="line"><span class="comment">#获取属性名字</span></span><br><span class="line"><span class="built_in">print</span>(content.get_attribute(<span class="string">&quot;class&quot;</span>))</span><br><span class="line"><span class="comment">#获取标签名字</span></span><br><span class="line"><span class="built_in">print</span>(content.tag_name)</span><br><span class="line"><span class="comment">#获取元素文本</span></span><br><span class="line"><span class="built_in">print</span>(content.find_elements_by_link_text(<span class="string">&#x27;新闻&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="交互"><a href="#交互" class="headerlink" title="交互"></a>交互</h3><p>获取对象后</p>
<p>click（）单击事件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入selenium</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="comment">#2.创建浏览器操作对象</span></span><br><span class="line">path=<span class="string">&#x27;chromedriver2.exe&#x27;</span></span><br><span class="line">browser=webdriver.Chrome(path)</span><br><span class="line"><span class="comment">#3.访问网站</span></span><br><span class="line">url=<span class="string">&#x27;https://baidu.com/&#x27;</span></span><br><span class="line">browser.get(url)</span><br><span class="line"><span class="comment">#根据id的值找到对象</span></span><br><span class="line">content=browser.find_element_by_id(<span class="string">&#x27;kw&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#给对象设置值</span></span><br><span class="line">content.send_keys(<span class="string">&#x27;周杰伦&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#获取百度一下，并且触发单机事件</span></span><br><span class="line">browser.find_element_by_id(<span class="string">&#x27;su&#x27;</span>).click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#滑到底部</span></span><br><span class="line">js_bottom=<span class="string">&#x27;document.documentElement.scrollTop=100000&#x27;</span></span><br><span class="line">browser.execute_script(js_bottom)</span><br><span class="line"><span class="comment">#获取下一页按钮，并且单机</span></span><br><span class="line">browser.find_element_by_xpath(<span class="string">&quot;//a[@class=&#x27;n&#x27;]&quot;</span>).click()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#后退</span></span><br><span class="line">browser.back()</span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#前进</span></span><br><span class="line">browser.forward()</span><br></pre></td></tr></table></figure>

<h3 id="phantomjs"><a href="#phantomjs" class="headerlink" title="phantomjs"></a>phantomjs</h3><p>公司倒闭了，不用了</p>
<h3 id="chrome-handless"><a href="#chrome-handless" class="headerlink" title="chrome handless"></a>chrome handless</h3><p>上面是自己写的，有错，以后排错</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from selenium import webdriver</span></span><br><span class="line"><span class="comment"># from selenium.webdriver.chrome.options import Options</span></span><br><span class="line"><span class="comment"># def share_browser():</span></span><br><span class="line"><span class="comment">#     chrome_options = Options</span></span><br><span class="line"><span class="comment">#     chrome_options.add_argument(&#x27;--headless&#x27;)</span></span><br><span class="line"><span class="comment">#     chrome_options.add_argument(&#x27;--disable-gpu&#x27;)</span></span><br><span class="line"><span class="comment">#     # path是你自己的chrome浏览器的文件路径</span></span><br><span class="line"><span class="comment">#     path = r&#x27;C:\Program Files (x86)\Google\Chrome\Applicationl\chrome.exe&#x27;</span></span><br><span class="line"><span class="comment">#     chrome_options.binary_location = path</span></span><br><span class="line"><span class="comment">#     browser = webdriver.Chrome( chrome_options=chrome_options)</span></span><br><span class="line"><span class="comment">#     return browser</span></span><br><span class="line"><span class="comment"># browser=share_browser()</span></span><br><span class="line"><span class="comment"># url = &#x27;https://www.baidu.com&#x27;</span></span><br><span class="line"><span class="comment"># browser.get(url)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line">chrome_options = Options()</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;‐‐headless&#x27;</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">&#x27;‐‐disable‐gpu&#x27;</span>)</span><br><span class="line"><span class="comment"># path是你自己的chrome浏览器的文件路径</span></span><br><span class="line">path = <span class="string">r&#x27;C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe&#x27;</span></span><br><span class="line">chrome_options.binary_location = path</span><br><span class="line">browser = webdriver.Chrome(chrome_options=chrome_options)</span><br><span class="line">browser.get(<span class="string">&#x27;http://www.baidu.com/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h1><p>官方文档<code>https://docs.python-requests.org/zh_CN/latest/</code></p>
<p>快速上手<code>https://docs.python-requests.org/zh_CN/latest/user/quickstart.html</code></p>
<h2 id="一个类型，六个属性"><a href="#一个类型，六个属性" class="headerlink" title="一个类型，六个属性"></a>一个类型，六个属性</h2><p>类型：&lt;class ‘requests.models.Response’&gt;</p>
<p>属性</p>
<ol>
<li>encoding设置编码</li>
<li>text获取源码</li>
<li>url获取访问的url   <a target="_blank" rel="noopener" href="https://www.baidu.com/">https://www.baidu.com/</a></li>
<li>content获取响应的二进制文件</li>
<li>status_code获取响应的状态码  200</li>
<li>headers响应头信息</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment">#一个类型，六个属性</span></span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/&#x27;</span></span><br><span class="line">r=requests.get(url)</span><br><span class="line"><span class="comment">#一个类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(r))</span><br><span class="line"><span class="comment">#属性1：encoding设置编码</span></span><br><span class="line">r.encoding=<span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"><span class="comment">#属性2：text获取源码</span></span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br><span class="line"><span class="comment">#属性3:url获取访问的url   https://www.baidu.com/</span></span><br><span class="line"><span class="built_in">print</span>(r.url)</span><br><span class="line"><span class="comment">#属性4:content获取响应的字节文件</span></span><br><span class="line"><span class="built_in">print</span>(r.content)</span><br><span class="line"><span class="comment">#属性5:status_code获取响应的状态码  200</span></span><br><span class="line"><span class="built_in">print</span>(r.status_code)</span><br><span class="line"><span class="comment">#属性6:headers响应头信息</span></span><br><span class="line"><span class="built_in">print</span>(r.headers)</span><br></pre></td></tr></table></figure>

<h2 id="get请求"><a href="#get请求" class="headerlink" title="get请求"></a>get请求</h2><p>( 1)参数使用params传递</p>
<p>(2）参数无需urlencode编码</p>
<p>( 3 )不需要请求对象的定制</p>
<p>(4)请求资源路径中的?可以加也可以不加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>:<span class="string">&#x27;教父&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r=requests.get(url=url,params=data,headers=headers)</span><br><span class="line"><span class="built_in">print</span>(r.text)</span><br></pre></td></tr></table></figure>

<h2 id="post请求-1"><a href="#post请求-1" class="headerlink" title="post请求"></a>post请求</h2><p>( 1 ) post请求是不需要编解码</p>
<p>( 2 ) post请求的参数是data</p>
<p>(3)不需要请求对象的定制</p>
<p>print(json.loads(con))行</p>
<p>print(json.loads(con,encoding=’utf-8’))不行</p>
<p>待议</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;kw&#x27;</span>:<span class="string">&#x27;love&#x27;</span>,</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">r=requests.post(url=url,data=data,headers=headers)</span><br><span class="line">con=r.text</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="built_in">print</span>(json.loads(con))</span><br><span class="line"></span><br><span class="line"><span class="comment">#详细翻译</span></span><br><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://fanyi.baidu.com/v2transapi?from=en&amp;to=zh&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Cookie&#x27;</span>:<span class="string">&#x27;太长了，自己复制&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="comment">#&#x27;from&#x27;: &#x27;en&#x27;,</span></span><br><span class="line">    <span class="comment">#&#x27;to&#x27;: &#x27;zh&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;query&#x27;</span>: <span class="string">&#x27;love&#x27;</span>,</span><br><span class="line">    <span class="comment">#&#x27;transtype&#x27;: &#x27;realtime&#x27;,</span></span><br><span class="line">    <span class="comment">#&#x27;simple_means_flag&#x27;: &#x27;3&#x27;,</span></span><br><span class="line">    <span class="string">&#x27;sign&#x27;</span>: <span class="string">&#x27;198772.518981&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;token&#x27;</span>: <span class="string">&#x27;7c22a0f4da3e8a49773d905ecf4b6211&#x27;</span>,</span><br><span class="line">    <span class="comment">#&#x27;domain&#x27;: &#x27;common&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r=requests.post(url=url,data=data,headers=headers)</span><br><span class="line">con=r.text</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="built_in">print</span>(json.loads(con))</span><br></pre></td></tr></table></figure>

<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>get,post后面直接使用<code>proxies</code>属性即可</p>
<h2 id="验证码和xpath"><a href="#验证码和xpath" class="headerlink" title="验证码和xpath"></a>验证码和xpath</h2><p>古诗文网</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">&#x27;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#先下载网页，然后从里面提取想要的数据</span></span><br><span class="line">r=requests.get(url=url)</span><br><span class="line">response=r.text</span><br><span class="line"><span class="comment">#是用xpath取三个会变的变量 VIEWSTATE VIEWSTATEGENERATOR png_code</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.HTML(response)</span><br><span class="line">VIEWSTATE=tree.xpath(<span class="string">&#x27;//input[@id=&quot;__VIEWSTATE&quot;]/@value&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">VIEWSTATEGENERATOR=tree.xpath(<span class="string">&#x27;//input[@id=&quot;__VIEWSTATEGENERATOR&quot;]/@value&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">src=tree.xpath(<span class="string">&#x27;//img[@id=&quot;imgCode&quot;]/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">png_code=<span class="string">&#x27;https://so.gushiwen.cn&#x27;</span>+src</span><br><span class="line"><span class="comment">#获取图片用urlretrieve会访问两次，前后验证码不一致必出逻辑错误</span></span><br><span class="line"><span class="comment">#urllib.request.urlretrieve(url=png_code,filename=&#x27;img/code.jpg&#x27;)</span></span><br><span class="line">session=requests.session()</span><br><span class="line">resp=session.get(png_code)</span><br><span class="line">content_png=resp.content</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;img/code.jpg&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content_png)</span><br><span class="line">code_name=<span class="built_in">input</span>(<span class="string">&#x27;请输入验证码&#x27;</span>)</span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;__VIEWSTATE&#x27;</span>:VIEWSTATE,</span><br><span class="line">    <span class="string">&#x27;__VIEWSTATEGENERATOR&#x27;</span>:VIEWSTATEGENERATOR,</span><br><span class="line">    <span class="string">&#x27;from: http&#x27;</span>:<span class="string">&#x27;//so.gushiwen.cn/user/collect.aspx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;email&#x27;</span>:<span class="string">&#x27; 1939212190@qq.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;pwd&#x27;</span>:<span class="string">&#x27; mingyifan0.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;code&#x27;</span>:code_name,</span><br><span class="line">    <span class="string">&#x27;denglu&#x27;</span>:<span class="string">&#x27; 登录&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#通过session访问就成功，requests就不行</span></span><br><span class="line">con=session.post(url=url,data=data,headers=headers)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;html/gushiwen.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(con.text)</span><br></pre></td></tr></table></figure>

<h2 id="超级鹰"><a href="#超级鹰" class="headerlink" title="超级鹰"></a>超级鹰</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.导入requests</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> chaojiying.chaojiying <span class="keyword">import</span> Chaojiying_Client</span><br><span class="line"></span><br><span class="line">url=<span class="string">&#x27;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#x27;</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#先下载网页，然后从里面提取想要的数据</span></span><br><span class="line">r=requests.get(url=url)</span><br><span class="line">response=r.text</span><br><span class="line"><span class="comment">#是用xpath取三个会变的变量 VIEWSTATE VIEWSTATEGENERATOR png_code</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">tree=etree.HTML(response)</span><br><span class="line">VIEWSTATE=tree.xpath(<span class="string">&#x27;//input[@id=&quot;__VIEWSTATE&quot;]/@value&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">VIEWSTATEGENERATOR=tree.xpath(<span class="string">&#x27;//input[@id=&quot;__VIEWSTATEGENERATOR&quot;]/@value&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">src=tree.xpath(<span class="string">&#x27;//img[@id=&quot;imgCode&quot;]/@src&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">png_code=<span class="string">&#x27;https://so.gushiwen.cn&#x27;</span>+src</span><br><span class="line"><span class="comment">#获取图片用urlretrieve会访问两次，前后验证码不一致必出逻辑错误</span></span><br><span class="line"><span class="comment">#urllib.request.urlretrieve(url=png_code,filename=&#x27;img/code.jpg&#x27;)</span></span><br><span class="line"></span><br><span class="line">session=requests.session()</span><br><span class="line">resp=session.get(png_code)</span><br><span class="line">content_png=resp.content</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;img/code.jpg&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(content_png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chaojiying = Chaojiying_Client(<span class="string">&#x27;action&#x27;</span>, <span class="string">&#x27;action&#x27;</span>, <span class="string">&#x27;923146&#x27;</span>)   <span class="comment">#用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line">im = <span class="built_in">open</span>(<span class="string">&#x27;img/code.jpg&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>).read()                                     <span class="comment">#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//</span></span><br><span class="line">code=chaojiying.PostPic(im, <span class="number">1902</span>).get(<span class="string">&#x27;pic_str&#x27;</span>)                              <span class="comment">#1902 验证码类型  官方网站&gt;&gt;价格体系 3.4+版 print 后要加()</span></span><br><span class="line"><span class="built_in">print</span>(code)</span><br><span class="line"></span><br><span class="line">data=&#123;</span><br><span class="line">    <span class="string">&#x27;__VIEWSTATE&#x27;</span>:VIEWSTATE,</span><br><span class="line">    <span class="string">&#x27;__VIEWSTATEGENERATOR&#x27;</span>:VIEWSTATEGENERATOR,</span><br><span class="line">    <span class="string">&#x27;from: http&#x27;</span>:<span class="string">&#x27;//so.gushiwen.cn/user/collect.aspx&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;email&#x27;</span>:<span class="string">&#x27; 1939212190@qq.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;pwd&#x27;</span>:<span class="string">&#x27; mingyifan0.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;code&#x27;</span>:code,</span><br><span class="line">    <span class="string">&#x27;denglu&#x27;</span>:<span class="string">&#x27; 登录&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#通过session访问就成功，requests就不行</span></span><br><span class="line">con=session.post(url=url,data=data,headers=headers)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;html/gushiwen.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)<span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(con.text)</span><br></pre></td></tr></table></figure>

<h1 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h1><blockquote>
<p>最重要的：start_urls末尾千万不要加“杠”，否则就会一直运行不出来（如果请求是html结尾的话）</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/scrapy-detail.html">https://www.runoob.com/w3cnote/scrapy-detail.html</a></p>
<p><img src="https://gitee.com/wangyi12/pic-bed/raw/master/img/image-20211004124112069.png" alt="image-20211004124112069"></p>
<blockquote>
<p> setting里的<code>ROBOTSTXT_OBEY = True</code>防君子不防我们。记得注释掉</p>
</blockquote>
<p>安装scrapy<code>D:\study\py\Scripts&gt;pip install scrapy -i http://pypi.douban.com/simple/</code></p>
<p>创建项目<code>D:\poject\python\p1&gt;scrapy startproject scrapy_baidu_01</code></p>
<p>项目不能已数字开头，不能含中文</p>
<p>创建爬虫文件<code>D:\poject\python\p1\scrapy_baidu_01\scrapy_baidu_01\spiders&gt;scrapy genspider baidu www.baidu.com</code></p>
<p>spiders下面<code>scrapy crawl 爬虫名字</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">D:\poject\python\p1&gt;scrapy startproject 项目名字</span><br><span class="line">D:\poject\python\p1\scrapy_baidu_01\scrapy_baidu_01\spiders&gt;scrapy genspider 爬虫名字 要访问的地址</span><br><span class="line">D:\poject\python\p1\wbtc\wbtc\spiders&gt;scrapy crawl 爬虫名字</span><br></pre></td></tr></table></figure>

<h2 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h2><p>1:text获取的是字符源码<br>2:body获取的二进制</p>
<p>3:xpath可以直接解析xpath网页的内容<br>4:extract提取seletor对象的值<br>5:extract_list提取seletor列表的值</p>
<h3 id="爬取58同城"><a href="#爬取58同城" class="headerlink" title="爬取58同城"></a>爬取58同城</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TcSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;tc&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;https://kaifeng.58.com/sou/?key=%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://kaifeng.58.com/sou/?key=%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91&#x27;</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment">#1:text获取的是字符源码</span></span><br><span class="line">        <span class="comment">#print(response.text)</span></span><br><span class="line">        <span class="comment">#2:body获取的二进制</span></span><br><span class="line">        <span class="comment"># print(&quot;==============================&quot;)</span></span><br><span class="line">        <span class="comment"># print(response.body)</span></span><br><span class="line">        <span class="comment">#3:xpath可以直接解析xpath网页的内容</span></span><br><span class="line">        <span class="comment">#xp=response.xpath(&#x27;//div[@class=&quot;tabs&quot;]/a/span&#x27;)[0]</span></span><br><span class="line">        <span class="comment">#4:extract提取seletor对象的值</span></span><br><span class="line">        <span class="comment">#5:extract_list提取seletor列表的值</span></span><br><span class="line">        xp=response.xpath(<span class="string">&#x27;//div[@class=&quot;tabs&quot;]/a/span&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==============================&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==============================&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(xp)</span><br><span class="line">        <span class="built_in">print</span>(xp.extract())</span><br><span class="line">        <span class="comment">#xp=response.xpath(&#x27;//input[@id=&quot;searchbtn&quot;]/@value&#x27;)[0]</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;==============================&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="爬取汽车之家（使用extract）"><a href="#爬取汽车之家（使用extract）" class="headerlink" title="爬取汽车之家（使用extract）"></a>爬取汽车之家（使用extract）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZjSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;zj&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;https://car.autohome.com.cn/price/brand-15.html&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://car.autohome.com.cn/price/brand-15.html&#x27;</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        name_list=response.xpath(<span class="string">&#x27;//div[@class=&quot;list-cont-main&quot;]/div[@class=&quot;main-title&quot;]/a/text()&#x27;</span>)</span><br><span class="line">        money_list=response.xpath(<span class="string">&#x27;//span[@class=&quot;lever-price red&quot;]/span/text()&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;===========================&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(name_list)):</span><br><span class="line">            <span class="built_in">print</span>(name_list[i].extract(),money_list[i].extract())</span><br></pre></td></tr></table></figure>

<h2 id="scrapy-shell"><a href="#scrapy-shell" class="headerlink" title="scrapy shell"></a>scrapy shell</h2><p>C:\Users\Administrator&gt;scrapy shell <a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com</a></p>
<p>C:\Users\Administrator&gt;scrapy shell <a target="_blank" rel="noopener" href="http://www.baidu.com/">http://www.baidu.com</a></p>
<p>直接cmd里直接输入即可，不用进ipython</p>
<h3 id="使用extract-first"><a href="#使用extract-first" class="headerlink" title="使用extract_first"></a>使用extract_first</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">6</span>]: response.xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span>)</span><br><span class="line">Out[<span class="number">6</span>]: [&lt;Selector xpath=<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span> data=<span class="string">&#x27;百度一下&#x27;</span>&gt;]</span><br><span class="line">In [<span class="number">7</span>]: a=response.xpath(<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span>)</span><br><span class="line">In [<span class="number">8</span>]: a.extract_first</span><br><span class="line">Out[<span class="number">8</span>]: &lt;bound method SelectorList.get of [&lt;Selector xpath=<span class="string">&#x27;//input[@id=&quot;su&quot;]/@value&#x27;</span> data=<span class="string">&#x27;百度一下&#x27;</span>&gt;]&gt;</span><br><span class="line">In [<span class="number">9</span>]: a.extract_first()</span><br><span class="line">Out[<span class="number">9</span>]: <span class="string">&#x27;百度一下&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="爬取当当网"><a href="#爬取当当网" class="headerlink" title="爬取当当网"></a>爬取当当网</h2><h3 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> dangdangwang.items <span class="keyword">import</span> DangdangwangItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;dangdang&#x27;</span></span><br><span class="line">    <span class="comment">#爬取多页的时候，只要域名就够了</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;category.dangdang.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://category.dangdang.com/cp01.01.02.00.00.00.html&#x27;</span>]</span><br><span class="line">    page=<span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=================&quot;</span>)</span><br><span class="line">        <span class="comment">#使用xpath筛选需要的三组</span></span><br><span class="line">        <span class="comment">#//ul[@class=&quot;bigimg&quot;]/li/a/img/@src</span></span><br><span class="line">        <span class="comment">#//ul[@class=&quot;bigimg&quot;]/li/a/img/@data-original/text()</span></span><br><span class="line">        <span class="comment">#//ul[@class=&quot;bigimg&quot;]/li/p[@class=&quot;price&quot;]/span[1]/text()</span></span><br><span class="line">        <span class="comment">#减少冗余，xpath内的元素还可以xpath叠加</span></span><br><span class="line">        li_list=response.xpath(<span class="string">&#x27;//ul[@class=&quot;bigimg&quot;]/li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> li_list:</span><br><span class="line">            src=i.xpath(<span class="string">&#x27;.//img/@data-original&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment">#第一个图片地址不一样，特殊对待</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> src:</span><br><span class="line">                src=i.xpath(<span class="string">&#x27;.//img/@src&#x27;</span>).extract_first()</span><br><span class="line">            title=i.xpath(<span class="string">&#x27;.//img/@alt&#x27;</span>).extract_first()</span><br><span class="line">            money=i.xpath(<span class="string">&#x27;.//p[@class=&quot;price&quot;]/span[1]/text()&#x27;</span>).extract_first()</span><br><span class="line">            <span class="comment">#if png_list[i]:</span></span><br><span class="line">            <span class="comment"># print(src,title,money)</span></span><br><span class="line">            book=DangdangwangItem(src=src,title=title,money=money)</span><br><span class="line">            <span class="keyword">yield</span> book</span><br><span class="line">            <span class="comment">#应该是用了递归调用自己，然后100自动停</span></span><br><span class="line">            <span class="keyword">if</span> self.page&lt;<span class="number">100</span>:</span><br><span class="line">                self.page=self.page+<span class="number">1</span></span><br><span class="line">                url=<span class="string">f&quot;http://category.dangdang.com/pg<span class="subst">&#123;self.page&#125;</span>-cp01.01.02.00.00.00.html&quot;</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url,callback=self.parse)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define here the models for your scraped items</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See documentation in:</span></span><br><span class="line"><span class="comment"># https://docs.scrapy.org/en/latest/topics/items.html</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangwangItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    src=scrapy.Field()</span><br><span class="line">    title=scrapy.Field()</span><br><span class="line">    money=scrapy.Field()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># useful for handling different item types with a single interface</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="comment">#https://img3m6.ddimg.cn/25/7/28525786-1_b_6.jpg</span></span><br><span class="line"><span class="comment">#http://img3m6.ddimg.cn/25/7/28525786-1_u_6.jpg</span></span><br><span class="line"><span class="comment">#要想使用管道必须先去setting里面打开</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangwangPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp=<span class="built_in">open</span>(<span class="string">&#x27;./json/book.json&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment">#write必须是str，强转即可</span></span><br><span class="line">        <span class="comment">#这个方法频繁操作文件，不常用</span></span><br><span class="line">       <span class="comment"># with open(&#x27;book.json&#x27;,&#x27;a&#x27;,encoding=&#x27;utf-8&#x27;)as fp:</span></span><br><span class="line">       <span class="comment">#     fp.write(str(item))</span></span><br><span class="line">        self.fp.write(<span class="built_in">str</span>(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义管道类</span></span><br><span class="line"><span class="comment">#setting里开启管道类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangloadPipeline</span>:</span></span><br><span class="line">    <span class="comment">#一定要return item</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        base_url=item.get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">        <span class="comment"># url = &#x27;https://img3m6.ddimg.cn/25/7/28525786-1_b_6.jpg&#x27;</span></span><br><span class="line">        <span class="comment"># sp = url.split(&#x27;_b_&#x27;, 1)</span></span><br><span class="line">        <span class="comment"># print(sp[0] + &#x27;_u_&#x27; + sp[1])</span></span><br><span class="line">        sp=base_url.split(<span class="string">&#x27;_b_&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">        url=<span class="string">&#x27;https:&#x27;</span>+sp[<span class="number">0</span>] + <span class="string">&#x27;_u_&#x27;</span> + sp[<span class="number">1</span>]</span><br><span class="line">        <span class="built_in">print</span>(url,<span class="built_in">type</span>(sp[<span class="number">0</span>]))</span><br><span class="line">        filename=<span class="string">&#x27;./books/&#x27;</span>+item.get(<span class="string">&#x27;title&#x27;</span>)+<span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">        urllib.request.urlretrieve(url=url,filename=filename)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mieleizhi0522/article/details/82142856">https://blog.csdn.net/mieleizhi0522/article/details/82142856</a></p>
<p>简单来说就是return,每次获得后面的对象的时候，进入管道</p>
<h3 id="管道封装"><a href="#管道封装" class="headerlink" title="管道封装"></a>管道封装</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#要想使用管道必须先去setting里面打开</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangwangPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp=<span class="built_in">open</span>(<span class="string">&#x27;book1.json&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment">#write必须是str，强转即可</span></span><br><span class="line">        <span class="comment">#这个方法频繁操作文件，不常用</span></span><br><span class="line">       <span class="comment"># with open(&#x27;book.json&#x27;,&#x27;a&#x27;,encoding=&#x27;utf-8&#x27;)as fp:</span></span><br><span class="line">       <span class="comment">#     fp.write(str(item))</span></span><br><span class="line">        self.fp.write(<span class="built_in">str</span>(item))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp.close()</span><br></pre></td></tr></table></figure>

<h3 id="多条管道同时i下载"><a href="#多条管道同时i下载" class="headerlink" title="多条管道同时i下载"></a>多条管道同时i下载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义管道类</span></span><br><span class="line"><span class="comment">#setting里开启管道类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DangdangloadPipeline</span>:</span></span><br><span class="line">    <span class="comment">#一定要return item</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        base_url=item.get(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">        <span class="comment"># url = &#x27;https://img3m6.ddimg.cn/25/7/28525786-1_b_6.jpg&#x27;  这段是下载原图，字符串拼接</span></span><br><span class="line">        <span class="comment"># sp = url.split(&#x27;_b_&#x27;, 1)</span></span><br><span class="line">        <span class="comment"># print(sp[0] + &#x27;_u_&#x27; + sp[1])</span></span><br><span class="line">        sp=base_url.split(<span class="string">&#x27;_b_&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">        url=<span class="string">&#x27;https:&#x27;</span>+sp[<span class="number">0</span>] + <span class="string">&#x27;_u_&#x27;</span> + sp[<span class="number">1</span>]</span><br><span class="line">        <span class="built_in">print</span>(url,<span class="built_in">type</span>(sp[<span class="number">0</span>]))</span><br><span class="line">        filename=<span class="string">&#x27;./books/&#x27;</span>+item.get(<span class="string">&#x27;title&#x27;</span>)+<span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">        urllib.request.urlretrieve(url=url,filename=filename)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<h3 id="多页数据同时下载"><a href="#多页数据同时下载" class="headerlink" title="多页数据同时下载"></a>多页数据同时下载</h3><p>​    <a target="_blank" rel="noopener" href="https://blog.csdn.net/ZHUYAN1209/article/details/104305066">https://blog.csdn.net/ZHUYAN1209/article/details/104305066</a></p>
<p>核心meta</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TtSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;tt&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.dydytt.net&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;http://dydytt.net/html/gndy/dyzz/index.html&#x27;</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># base_url = response.xpath(&#x27;//div[@class=&quot;co_content8&quot;]//b/a&#x27;)</span></span><br><span class="line">        href_list=response.xpath(<span class="string">&#x27;//div[@class=&quot;co_content8&quot;]//b/a/@href&#x27;</span>)</span><br><span class="line">        name_list=response.xpath(<span class="string">&#x27;//div[@class=&quot;co_content8&quot;]//b/a/text()&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;==================================&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;==================================&#x27;</span>)</span><br><span class="line">        <span class="comment">#提前取出来，每次遍历都是一个元素，不用extract_first，然后直接使用extract取里面的数值就行了</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(href_list)):</span><br><span class="line">            href=<span class="string">&#x27;https://www.dydytt.net&#x27;</span>+href_list[i].extract()</span><br><span class="line">            name=name_list[i].extract()</span><br><span class="line">            <span class="built_in">print</span>(href,name)</span><br><span class="line">            <span class="comment"># for i in href_list:</span></span><br><span class="line">            <span class="comment">#     href=i.extract()</span></span><br><span class="line">            <span class="comment">#     print(href)</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=href,callback=self.parse_secod,meta=&#123;<span class="string">&#x27;name&#x27;</span>:name&#125;)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_secod</span>(<span class="params">self,response</span>):</span></span><br><span class="line">        src=response.xpath(<span class="string">&quot;//div[@class=&#x27;co_content8&#x27;]//img/@src&quot;</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        name=response.meta[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;===========================&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(src,name)</span><br><span class="line">        <span class="comment">#一个dyt，两个话的不报错，但实际运行错误</span></span><br><span class="line">        <span class="keyword">from</span> dyt.items <span class="keyword">import</span> DytItem</span><br><span class="line">        movie=DytItem(src=src,name=name)</span><br><span class="line">        <span class="keyword">yield</span> movie</span><br></pre></td></tr></table></figure>



<h1 id="crawl爬取读书网"><a href="#crawl爬取读书网" class="headerlink" title="crawl爬取读书网"></a>crawl爬取读书网</h1><p>创建项目的时候用这个  D:\poject\python\p1\dushuwang\dushuwang\spiders&gt; scrapy genspider -t crawl  爬虫名字   要爬的网站</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DSpider</span>(<span class="params">CrawlSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;d&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.dushu.com&#x27;</span>]</span><br><span class="line">    <span class="comment">#记得去两端的http和 杠    后面加_1是为了保证起始页也能爬到</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.dushu.com/book/1206_1.html&#x27;</span>]</span><br><span class="line">    rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r&#x27;/book/1206_\d+\.html&#x27;</span>), callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=============================&#x27;</span>)</span><br><span class="line">        base=response.xpath(<span class="string">&#x27;//div[@class=&quot;book-info&quot;]//a/img&#x27;</span>)</span><br><span class="line">        <span class="comment"># src_list=response.xpath(&#x27;//div[@class=&quot;book-info&quot;]//a/img/@src&#x27;)</span></span><br><span class="line">        <span class="comment"># name_list=response.xpath(&#x27;//div[@class=&quot;book-info&quot;]//a/img/@alt&#x27;)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> base:</span><br><span class="line">            src=i.xpath(<span class="string">&#x27;./@data-original&#x27;</span>).extract_first()</span><br><span class="line">            name=i.xpath(<span class="string">&#x27;./@alt&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(src,name)</span><br><span class="line">            <span class="comment">#不需要两个，两个是错的，一个报错但是对</span></span><br><span class="line">            <span class="keyword">from</span> dushuwang.items <span class="keyword">import</span> DushuwangItem</span><br><span class="line">            book=DushuwangItem(src=src,name=name)</span><br><span class="line">            <span class="keyword">yield</span> book</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#setting里开启管道</span></span><br><span class="line">DB_HOST=<span class="string">&#x27;127.0.0.1&#x27;</span></span><br><span class="line">DB_PROT=<span class="number">3306</span></span><br><span class="line">DB_USER=<span class="string">&#x27;root&#x27;</span></span><br><span class="line">DB_PWD=<span class="string">&#x27;123456&#x27;</span></span><br><span class="line">DB_NAME=<span class="string">&#x27;python&#x27;</span></span><br><span class="line">DB_CHARSET=<span class="string">&#x27;utf8&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 管道是下载的东西</span></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">from</span> itemadapter <span class="keyword">import</span> ItemAdapter</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DushuwangPipeline</span>:</span></span><br><span class="line"><span class="comment">#记得去开启300的管道</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp=<span class="built_in">open</span>(<span class="string">&#x27;book.json&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        <span class="comment">#write必须是str，强转即可</span></span><br><span class="line">        <span class="comment">#这个方法频繁操作文件，不常用</span></span><br><span class="line">        self.fp.write(<span class="built_in">str</span>(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.fp.close()</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        <span class="comment"># DB_HOST = &#x27;127.0.0.1&#x27;</span></span><br><span class="line">        <span class="comment"># DB_PROT = 3306</span></span><br><span class="line">        <span class="comment"># DB_USER = &#x27;root&#x27;</span></span><br><span class="line">        <span class="comment"># DB_PWD = &#x27;123456&#x27;</span></span><br><span class="line">        <span class="comment"># DB_NAME = &#x27;python&#x27;</span></span><br><span class="line">        <span class="comment"># DB_CHARSET = &#x27;utf8&#x27;</span></span><br><span class="line">        setting=get_project_settings()</span><br><span class="line">        self.host=setting[<span class="string">&#x27;DB_HOST&#x27;</span>]</span><br><span class="line">        self.prot=setting[<span class="string">&#x27;DB_PROT&#x27;</span>]</span><br><span class="line">        self.user=setting[<span class="string">&#x27;DB_USER&#x27;</span>]</span><br><span class="line">        self.pwd=setting[<span class="string">&#x27;DB_PWD&#x27;</span>]</span><br><span class="line">        self.name=setting[<span class="string">&#x27;DB_NAME&#x27;</span>]</span><br><span class="line">        self.charset=setting[<span class="string">&#x27;DB_CHARSET&#x27;</span>]</span><br><span class="line">        self.connect()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self</span>):</span></span><br><span class="line">       self.conn=pymysql.connect(</span><br><span class="line">           host=self.host,</span><br><span class="line">           port=self.prot,</span><br><span class="line">           user=self.user,</span><br><span class="line">           password=self.pwd,</span><br><span class="line">           db=self.name,</span><br><span class="line">           charset=self.charset</span><br><span class="line">       )</span><br><span class="line">       self.cursor=self.conn.cursor()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        sql=<span class="string">&#x27;insert into dushuwang(name,src) values(&quot;&#123;&#125;&quot;,&quot;&#123;&#125;&quot;)&#x27;</span>.<span class="built_in">format</span>(item[<span class="string">&quot;name&quot;</span>],item[<span class="string">&quot;src&quot;</span>])</span><br><span class="line">        self.cursor.execute(sql)</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self,spider</span>):</span></span><br><span class="line">        self.cursor.close()</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#item是对象s</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DushuwangItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment">#filed是方法需要带括号</span></span><br><span class="line">    src=scrapy.Field()</span><br><span class="line">    name=scrapy.Field()</span><br></pre></td></tr></table></figure>

<h2 id="scrapy的post"><a href="#scrapy的post" class="headerlink" title="scrapy的post"></a>scrapy的post</h2><p>post请求必须需要用<code>start_request</code>，原来的请求只能处理get请求，post请求需要带参数</p>
<p>json.loads没有encoding选项时候，直接运行下，说不定默认utf-8</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;p&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&#x27;https://fanyi.baidu.com/sug&#x27;]</span></span><br><span class="line">    <span class="comment"># post请求不带参数就无任何意义</span></span><br><span class="line">    <span class="comment"># def parse(self, response):</span></span><br><span class="line">    <span class="comment">#     pass</span></span><br><span class="line">    <span class="comment">#需要使用start_request</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span>(<span class="params">self</span>):</span></span><br><span class="line">        url=<span class="string">&#x27;https://fanyi.baidu.com/sug&#x27;</span></span><br><span class="line">        data=&#123;</span><br><span class="line">            <span class="string">&#x27;kw&#x27;</span>: <span class="string">&#x27;love&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> scrapy.FormRequest(url=url,formdata=data,callback=self.parse_second)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_second</span>(<span class="params">self,response</span>):</span></span><br><span class="line">        content=response.text</span><br><span class="line">        <span class="comment">#没有encoding</span></span><br><span class="line">        obj=json.loads(content)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;=============&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(obj)</span><br></pre></td></tr></table></figure>



<h1 id="bing壁纸"><a href="#bing壁纸" class="headerlink" title="bing壁纸"></a>bing壁纸</h1><p>算是小目标了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down</span>(<span class="params">page</span>):</span></span><br><span class="line">    url=<span class="string">f&quot;https://bing.ioliu.cn/ranking?p=<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">    response=requests.get(url=url,headers=headers)</span><br><span class="line">    content=response.content</span><br><span class="line">    tree=etree.HTML(content)</span><br><span class="line">    res=tree.xpath(<span class="string">&#x27;//img[@class=&quot;progressive__img progressive--not-loaded&quot;]/@data-progressive&#x27;</span>)</span><br><span class="line">    name_list=tree.xpath(<span class="string">&#x27;//h3/text()&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res)):</span><br><span class="line">        res[i]=res[i].replace(<span class="string">&#x27;_640x480&#x27;</span>,<span class="string">&#x27;_1920x1080&#x27;</span>)</span><br><span class="line">        urllib.request.urlretrieve(url=res[i], filename=<span class="built_in">str</span>(name_list[i]).split(<span class="string">&#x27;/&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(name_list[i])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;第<span class="subst">&#123;page&#125;</span>页已完成&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;批量下载bing（https://cn.bing.com/）的壁纸（https://bing.ioliu.cn/ranking）&quot;</span>)</span><br><span class="line">    start=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;起始页&#x27;</span>))</span><br><span class="line">    end=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;终止页&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start,end+<span class="number">1</span>):</span><br><span class="line">        down(i)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完成，程序将在3秒后关闭&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完成，程序将在2秒后关闭&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载完成，程序将在1秒后关闭&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
    
      <div>
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:24px;">-------------一键三连加关注，包包金橙挡不住-------------</div>
    
</div>
      </div>
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>王一
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2021/10/19/python%E7%AC%94%E8%AE%B0/" title="python笔记">http://example.com/2021/10/19/python笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag"># 笔记</a>
              <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"># 爬虫</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/10/16/spring%E7%9A%84%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/" rel="prev" title="spring的常用配置">
      <i class="fa fa-chevron-left"></i> spring的常用配置
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/10/23/mybatis/" rel="next" title="mybatis笔记">
      mybatis笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81NDY4Ny8zMTE1OA=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%89%E8%A3%85"><span class="nav-number">1.</span> <span class="nav-text">安装</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#python"><span class="nav-number">1.1.</span> <span class="nav-text">python</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pip"><span class="nav-number">1.1.1.</span> <span class="nav-text">pip</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85pip"><span class="nav-number">1.1.2.</span> <span class="nav-text">安装pip</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%94%B9%E4%B8%8B%E8%BD%BD%E7%9A%84%E5%9C%B0%E5%9D%80"><span class="nav-number">1.1.3.</span> <span class="nav-text">更改下载的地址</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%90%E8%A1%8Cpython"><span class="nav-number">1.1.4.</span> <span class="nav-text">运行python</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pycharm"><span class="nav-number">1.2.</span> <span class="nav-text">pycharm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AF%8F%E6%AC%A1%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E6%B3%A8%E9%87%8A"><span class="nav-number">1.2.1.</span> <span class="nav-text">每次创建文件自动添加注释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B3%A8%E9%87%8A"><span class="nav-number">1.2.2.</span> <span class="nav-text">注释</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#python-1"><span class="nav-number">2.</span> <span class="nav-text">python</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">数据类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E5%8F%98%E9%87%8F%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.2.</span> <span class="nav-text">查看变量类型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83"><span class="nav-number">2.3.</span> <span class="nav-text">命名规范</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="nav-number">2.4.</span> <span class="nav-text">类型转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="nav-number">2.5.</span> <span class="nav-text">运算符</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#for"><span class="nav-number">2.6.</span> <span class="nav-text">for</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#list"><span class="nav-number">2.7.</span> <span class="nav-text">list</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E"><span class="nav-number">2.7.1.</span> <span class="nav-text">增</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0"><span class="nav-number">2.7.2.</span> <span class="nav-text">删</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%B9"><span class="nav-number">2.7.3.</span> <span class="nav-text">改</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5"><span class="nav-number">2.7.4.</span> <span class="nav-text">查</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%83%E7%BB%84"><span class="nav-number">2.8.</span> <span class="nav-text">元组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%87%E7%89%87"><span class="nav-number">2.9.</span> <span class="nav-text">切片</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%97%E5%85%B8"><span class="nav-number">2.10.</span> <span class="nav-text">字典</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E-1"><span class="nav-number">2.10.1.</span> <span class="nav-text">增</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0-1"><span class="nav-number">2.10.2.</span> <span class="nav-text">删</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%94%B9-1"><span class="nav-number">2.10.3.</span> <span class="nav-text">改</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9F%A5-1"><span class="nav-number">2.10.4.</span> <span class="nav-text">查</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%81%8D%E5%8E%86"><span class="nav-number">2.10.5.</span> <span class="nav-text">遍历</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E4%BB%B6"><span class="nav-number">3.</span> <span class="nav-text">文件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">3.1.</span> <span class="nav-text">序列化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">3.2.</span> <span class="nav-text">反序列化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%82%E5%B8%B8"><span class="nav-number">4.</span> <span class="nav-text">异常</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#urllib%E5%BA%93"><span class="nav-number">5.</span> <span class="nav-text">urllib库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%85%AD%E4%B8%AA%E6%96%B9%E6%B3%95"><span class="nav-number">5.1.</span> <span class="nav-text">一个类型，六个方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD"><span class="nav-number">5.2.</span> <span class="nav-text">下载</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%88%AC%E8%99%AB"><span class="nav-number">6.</span> <span class="nav-text">爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%B7%E6%B1%82%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%AE%9A%E5%88%B6%EF%BC%88UA%E5%8F%8D%E7%88%AC%EF%BC%89"><span class="nav-number">6.1.</span> <span class="nav-text">请求对象的定制（UA反爬）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#URL%E4%B8%AD%E6%9C%89%E4%B8%AD%E6%96%87%E7%9A%84%E6%97%B6%E5%80%99%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="nav-number">6.2.</span> <span class="nav-text">URL中有中文的时候的解决办法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#quote%E6%96%B9%E6%B3%95"><span class="nav-number">6.2.1.</span> <span class="nav-text">quote方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#urlencode%E6%96%B9%E6%B3%95"><span class="nav-number">6.2.2.</span> <span class="nav-text">urlencode方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#post%E8%AF%B7%E6%B1%82"><span class="nav-number">6.3.</span> <span class="nav-text">post请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get%E8%AF%B7%E6%B1%82%E6%89%B9%E9%87%8F%E7%88%AC%E5%8F%96%E3%80%82"><span class="nav-number">6.4.</span> <span class="nav-text">get请求批量爬取。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#post%E8%AF%B7%E6%B1%82%E7%88%AC%E5%8D%81%E9%A1%B5"><span class="nav-number">6.5.</span> <span class="nav-text">post请求爬十页</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#handle"><span class="nav-number">6.6.</span> <span class="nav-text">handle</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%B1%A0"><span class="nav-number">6.7.</span> <span class="nav-text">代理池</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%A7%A3%E6%9E%90"><span class="nav-number">7.</span> <span class="nav-text">解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Xpath-lxml"><span class="nav-number">7.1.</span> <span class="nav-text">Xpath(lxml)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="nav-number">7.1.1.</span> <span class="nav-text">基本语法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#jsonpath"><span class="nav-number">7.2.</span> <span class="nav-text">jsonpath</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BeautifulSoup-BS4"><span class="nav-number">7.3.</span> <span class="nav-text">BeautifulSoup(BS4)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#selenium"><span class="nav-number">7.4.</span> <span class="nav-text">selenium</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%BD%8D%E5%85%83%E7%B4%A0"><span class="nav-number">7.4.1.</span> <span class="nav-text">定位元素</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96%E5%85%83%E7%B4%A0%E4%BF%A1%E6%81%AF"><span class="nav-number">7.4.2.</span> <span class="nav-text">获取元素信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%A4%E4%BA%92"><span class="nav-number">7.4.3.</span> <span class="nav-text">交互</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#phantomjs"><span class="nav-number">7.4.4.</span> <span class="nav-text">phantomjs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chrome-handless"><span class="nav-number">7.4.5.</span> <span class="nav-text">chrome handless</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#requests"><span class="nav-number">8.</span> <span class="nav-text">requests</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E7%B1%BB%E5%9E%8B%EF%BC%8C%E5%85%AD%E4%B8%AA%E5%B1%9E%E6%80%A7"><span class="nav-number">8.1.</span> <span class="nav-text">一个类型，六个属性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get%E8%AF%B7%E6%B1%82"><span class="nav-number">8.2.</span> <span class="nav-text">get请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#post%E8%AF%B7%E6%B1%82-1"><span class="nav-number">8.3.</span> <span class="nav-text">post请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%90%86"><span class="nav-number">8.4.</span> <span class="nav-text">代理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%AA%8C%E8%AF%81%E7%A0%81%E5%92%8Cxpath"><span class="nav-number">8.5.</span> <span class="nav-text">验证码和xpath</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E7%BA%A7%E9%B9%B0"><span class="nav-number">8.6.</span> <span class="nav-text">超级鹰</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapy"><span class="nav-number">9.</span> <span class="nav-text">Scrapy</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="nav-number">9.1.</span> <span class="nav-text">基本方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%88%AC%E5%8F%9658%E5%90%8C%E5%9F%8E"><span class="nav-number">9.1.1.</span> <span class="nav-text">爬取58同城</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E6%B1%BD%E8%BD%A6%E4%B9%8B%E5%AE%B6%EF%BC%88%E4%BD%BF%E7%94%A8extract%EF%BC%89"><span class="nav-number">9.1.2.</span> <span class="nav-text">爬取汽车之家（使用extract）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#scrapy-shell"><span class="nav-number">9.2.</span> <span class="nav-text">scrapy shell</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8extract-first"><span class="nav-number">9.2.1.</span> <span class="nav-text">使用extract_first</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%88%AC%E5%8F%96%E5%BD%93%E5%BD%93%E7%BD%91"><span class="nav-number">9.3.</span> <span class="nav-text">爬取当当网</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#yield"><span class="nav-number">9.3.1.</span> <span class="nav-text">yield</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%A1%E9%81%93%E5%B0%81%E8%A3%85"><span class="nav-number">9.3.2.</span> <span class="nav-text">管道封装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%9D%A1%E7%AE%A1%E9%81%93%E5%90%8C%E6%97%B6i%E4%B8%8B%E8%BD%BD"><span class="nav-number">9.3.3.</span> <span class="nav-text">多条管道同时i下载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E9%A1%B5%E6%95%B0%E6%8D%AE%E5%90%8C%E6%97%B6%E4%B8%8B%E8%BD%BD"><span class="nav-number">9.3.4.</span> <span class="nav-text">多页数据同时下载</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#crawl%E7%88%AC%E5%8F%96%E8%AF%BB%E4%B9%A6%E7%BD%91"><span class="nav-number">10.</span> <span class="nav-text">crawl爬取读书网</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#scrapy%E7%9A%84post"><span class="nav-number">10.1.</span> <span class="nav-text">scrapy的post</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#bing%E5%A3%81%E7%BA%B8"><span class="nav-number">11.</span> <span class="nav-text">bing壁纸</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="王一"
      src="/images/1.gif">
  <p class="site-author-name" itemprop="name">王一</p>
  <div class="site-description" itemprop="description">你进入游戏行业，就是为了让孩子们上瘾，让人们点击广告吗———美食家五叔评《纪念碑谷》</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://zhongshengguji.github.io/" title="GitHub → https:&#x2F;&#x2F;zhongshengguji.github.io&#x2F;" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/zhong-sheng-gu-ji-24" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;zhong-sheng-gu-ji-24" rel="noopener" target="_blank"><i class="gratipay fa-fw"></i>知乎</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/jhfgjhg1" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;jhfgjhg1" rel="noopener" target="_blank"><i class="codiepie fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/82340048" title="B站 → https:&#x2F;&#x2F;space.bilibili.com&#x2F;82340048" rel="noopener" target="_blank"><i class="bold fa-fw"></i>B站</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="link fa-fw"></i>
      我的学校
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.bilibili.com/" title="https:&#x2F;&#x2F;www.bilibili.com&#x2F;" rel="noopener" target="_blank">B站</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.kfu.edu.cn/" title="http:&#x2F;&#x2F;www.kfu.edu.cn&#x2F;" rel="noopener" target="_blank">开封大学</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shanghuaxueyuan.com/" title="http:&#x2F;&#x2F;www.shanghuaxueyuan.com&#x2F;" rel="noopener" target="_blank">裳华职业技术中专</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-11 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">王一</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">278k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">4:13</span>
</div>
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共79.7k字</span>
</div>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
